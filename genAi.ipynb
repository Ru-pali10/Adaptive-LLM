{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: diptest in ./vir_env/lib/python3.10/site-packages (0.8.2)\n",
      "Requirement already satisfied: psutil in ./vir_env/lib/python3.10/site-packages (from diptest) (6.1.1)\n",
      "Requirement already satisfied: numpy>=1.18 in ./vir_env/lib/python3.10/site-packages (from diptest) (2.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai -q\n",
    "from openai import OpenAI\n",
    "%pip install diptest\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from diptest import diptest\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm  # For Gaussian fitting\n",
    "import seaborn as sns\n",
    "import json\n",
    "import io\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./vir_env/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./vir_env/lib/python3.10/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./vir_env/lib/python3.10/site-packages (from requests) (2024.12.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./vir_env/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./vir_env/lib/python3.10/site-packages (from requests) (3.4.1)\n",
      "IA32_FIXED_CTR1  PEBS:[NonPreciseEventingIP]  Architectural, Fixed, Speculative\n"
     ]
    }
   ],
   "source": [
    "!pip3 install requests\n",
    "import requests\n",
    "import sqlite3\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "def getData(url):\n",
    "    response = requests.get(url)\n",
    "    #convert to text string and return \n",
    "    return response.text\n",
    "\n",
    "\n",
    "url = 'https://perfmon-events.intel.com/ahybrid.html'\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 gecko/20100101 Firefox/102.0\"}\n",
    "html_doc = getData(url)\n",
    "soup = BeautifulSoup(html_doc,'html.parser')\n",
    "#print(soup)\n",
    "#2\n",
    "#table=soup.find('table',{'class':'sortable wikitable'})\n",
    "table=soup.find('table',{'id':'event_table'})\n",
    "#print(table)\n",
    "table_val=[]\n",
    "rows=table.find_all('tr')[2:]\n",
    "\n",
    "print(rows[1].find_all('td')[2].text)\n",
    "event_table={}\n",
    "for r in range(5,len(rows)):\n",
    "    td_tag=rows[r].find_all('td')\n",
    "    if(td_tag):\n",
    "        key = td_tag[0].text.strip()  # key\n",
    "        value = td_tag[2].text.split(\" \")[:2]  # Extract first two words from the 3rd column\n",
    "        event_table[key] = {\n",
    "            'config': value,  # Add the configuration field\n",
    "            'description': td_tag[1].text.strip()  # Extract the description from the 2nd column\n",
    "        }\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import tempfile\n",
    "\n",
    "class GPT:\n",
    "   \n",
    "    def __init__(self):\n",
    "        # Initialize the client with your API key\n",
    "        self.api_key = GPT.read_api_key()\n",
    "        self.client=OpenAI(api_key=self.api_key)\n",
    "        self.event_table=event_table\n",
    "        self.tools=[\n",
    "                {\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\":{\n",
    "                    \"name\": \"perform_bimodal_test\",\n",
    "                    \"description\": \"This function performs a diptest on the  HPC's values given by the user and assistant'll return the stats value if p value <0.05 then it is bimodal\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"filepath\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"perfmon event counter filepath eg filepath.txt\"\n",
    "                            }\n",
    "                            },\n",
    "                        \"required\": [\"filepath\"]\n",
    "                    }\n",
    "                }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": \"plot_a_graph\",\n",
    "                        \"description\": \"This function reads data from a file and plots a graph of the data. that show it is bimodal or what\",\n",
    "                        \"parameters\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"filepath\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"Path to the data file (e.g., filepath.txt).\"\n",
    "                                }\n",
    "                            },\n",
    "                            \"required\": [\"filepath\"]\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "       \n",
    "    @staticmethod\n",
    "    def read_api_key():\n",
    "        # Read the API key from the text file\n",
    "        try:\n",
    "            with open('adap_key', 'r') as file: # here your key location \n",
    "                api_key = file.read().strip()\n",
    "            return api_key\n",
    "        except FileNotFoundError:\n",
    "            raise Exception(\"API key file 'adap_key' not found.\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"An error occurred while reading the API key: {e}\")\n",
    "        \n",
    "    def get_gpt_response(self,messages):\n",
    "\n",
    "        try:\n",
    "            # Call the OpenAI ChatCompletion API\n",
    "           \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=messages,\n",
    "                tools=self.tools,\n",
    "                tool_choice=\"auto\",\n",
    "            )\n",
    "            # Extract and return the assistant's response\n",
    "            return  response\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"An error occurred while getting GPT response: {e}\")\n",
    "    def upload_file(self, filepath):\n",
    "        with open(filepath, 'rb') as file:\n",
    "            response = self.client.files.create(file=file, purpose=\"assistants\")\n",
    "        return response.id\n",
    "    def read_data_from_file(file_path):\n",
    "        \"\"\"Reads numeric data from a file, assuming one value per line.\"\"\"\n",
    "        data = []\n",
    "\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                data.extend([float(value) for value in line.strip().split()])\n",
    "        return data[:72000]\n",
    "\n",
    "    def perform_bimodal_test(filepath):\n",
    "        \"\"\"Performs the Dip Test on the data.\"\"\"\n",
    "        try:\n",
    "            # Read data from the file\n",
    "            data = GPT.read_data_from_file(filepath)\n",
    "            # Convert list to numpy array\n",
    "            data_array = np.array(data)\n",
    "            #print(data_array)\n",
    "            # Perform the Dip Test\n",
    "            dip_stat, p_value = diptest(data_array)\n",
    "            #print(f\"Dip stat: {dip_stat}, P-value: {p_value}\")  # Debug results\n",
    "\n",
    "            return f\"dip_stat: {dip_stat}, p_value: {p_value}\"\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "    def plot_a_graph(filepath):\n",
    "        try:\n",
    "            data=GPT.read_data_from_file(filepath)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.histplot(data, kde=True, bins=30, color=\"blue\", stat=\"density\", label=\"Histogram with KDE\")\n",
    "\n",
    "            # Add title and labels\n",
    "            plt.title(\"Check for Bimodality in Data\", fontsize=16)\n",
    "            plt.xlabel(\"Data Values\", fontsize=12)\n",
    "            plt.ylabel(\"Density\", fontsize=12)\n",
    "            plt.legend()\n",
    "            plt.grid(alpha=0.3)\n",
    "            # Save the plot to a temporary file\n",
    "            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".png\")\n",
    "            plt.savefig(temp_file.name, format=\"png\", bbox_inches=\"tight\")\n",
    "            \n",
    "            # Close the plot\n",
    "            plt.close()\n",
    "            \n",
    "            # Return the file path\n",
    "            return {\"image_path\": temp_file.name}\n",
    "            #plt.show()\n",
    "            '''buffer = io.BytesIO()\n",
    "            plt.savefig(buffer, format=\"png\")\n",
    "            buffer.seek(0)\n",
    "\n",
    "            plt.close()\n",
    "\n",
    "            # Encode the image as base64\n",
    "            img_base64 = base64.b64encode(buffer.read()).decode(\"utf-8\")\n",
    "            buffer.close()\n",
    "            return img_base64'''\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system :You are an assistant ,that gives a perfmon event counter from the site https://perfmon-events.intel.com/ to detect attack by given the decription of the attack and machine model\n"
     ]
    }
   ],
   "source": [
    "# Prepare your messages\n",
    "messages=[{'role': 'system', 'content': 'You are an assistant ,that gives a perfmon event counter from the site https://perfmon-events.intel.com/ to detect attack by given the decription of the attack and machine model'},\n",
    "      ]\n",
    "'''\n",
    "    {'role':'user','content':'I am performing a matrix multiplication of a 500x500 size matrix. Can you suggest list of  counters name for raptor lake system from intel perfmon that could potentially be used to detect attack on my victim code? '}\n",
    "        ]'''\n",
    "print(f\"system :{messages[0]['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an assistant ,that gives a perfmon event counter to detect attack by given the decription of the attack\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I am performing a matrix multiplication of a 500x500 size matrix. Can you suggest set of  counters name for raptor lake system from intel perfmon that could potentially be used to detect meltdown attack on my victim code?\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"To detect a Meltdown attack on your victim code using Intel Perfmon counters for the Raptor Lake system, you can consider the following set of counters:\\n\\n1. **INST_RETIRED.ANY**: Counts the number of instructions retired.\\n2. **CPU_CLK_UNHALTED.THREAD**: Counts the number of core clock cycles when the thread is running.\\n3. **MEM_INST_RETIRED.ALL_LOADS**: Counts the number of retired instructions that are data loads.\\n4. **MEM_INST_RETIRED.ALL_STORES**: Counts the number of retired instructions that are data stores.\\n5. **L2_TRANS.L2_WB**: Counts L2 cache writebacks.\\n6. **L2_RQSTS.ALL_CODE_RD**: Counts all code reads.\\n7. **ARITH.INST_RETIRED**: Counts the number of retired instructions that are arithmetic instructions.\\n\\nThese counters can provide insights into the behavior of the code and potential anomalies that could indicate a Meltdown attack. By monitoring these counters during the matrix multiplication operation, you can analyze if there are any sudden spikes or unusual patterns that might signal a Meltdown attack.\\n\\nWould you like to proceed with monitoring these counters using a performance monitoring event counter file (perfmon event counter)?\"\n",
    "        }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an assistant ,that gives a perfmon event counter from the site https://perfmon-events.intel.com/ to detect attack by given the decription of the attack and machine model'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_json(file_path, new_data):\n",
    "    try:\n",
    "        # Read the existing data from the file\n",
    "        try:\n",
    "            with open(file_path, \"r\") as file:\n",
    "                existing_data = json.load(file)  # Load existing JSON data\n",
    "        except (FileNotFoundError, json.JSONDecodeError):\n",
    "            existing_data = []  # If file doesn't exist or is empty, start with an empty list\n",
    "\n",
    "        # Append the new data\n",
    "        existing_data.append(new_data)\n",
    "\n",
    "        # Write the updated data back to the file\n",
    "        with open(file_path, \"w\") as file:\n",
    "            json.dump(existing_data, file, indent=4)  # Save the updated JSON\n",
    "        print(\"Messages successfully appended to all.json.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error appending to JSON file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user :\n",
      "I am performing RSA encryption and decryption.Can you suggest set of  counters name for alder lake system from intel perfmon that could potentially be used to detect speculative execution  with Croos-Modifying Code Machine Clear on my system..\n",
      "GPT Response: To detect speculative execution vulnerabilities such as \"Cross-Modifying Code\" on an Alder Lake system, you can refer to Intel's performance monitoring counters. Here are some potential perfmon event counters that may be helpful in this context:\n",
      "\n",
      "1. **IDQ_UOPS_NOT_DELIVERED.CORE**: Counts the number of Uops not delivered by the front end.\n",
      "\n",
      "2. **INT_MISC.RECOVERY_CYCLES**: Counts the number of cycles that the machine is recovering from previous mispredictions or interruptions.\n",
      "\n",
      "3. **CYCLES_ACTIVITY.CYCLES_NO_EXECUTE**: Counts the number of cycles where no instructions are executed.\n",
      "\n",
      "4. **MACHINE_CLEARS.SMC**: Counts the occurrences of Self-Modifying Code, which might trigger speculative execution vulnerabilities.\n",
      "\n",
      "5. **MACHINE_CLEARS.MEMORY_ORDERING**: Tracks machine clears due to memory ordering issues, potentially indicating mis-speculation.\n",
      "\n",
      "6. **MACHINE_CLEARS.MASKMOV**: Counts machine clears due to mask move operations.\n",
      "\n",
      "7. **RESOURCE_STALLS.RS**: Counts the number of cycles stalled due to resource-related reasons, possibly indicating speculative execution issues.\n",
      "\n",
      "These counters can be monitored using Intel's VTune Profiler or other performance monitoring tools that support perfmon events on Intel processors. Monitoring these counters may help in understanding and detecting potential speculative execution vulnerabilities triggered by Cross-Modifying Code scenarios.\n",
      "user :\n",
      "Messages successfully appended to all.json.\n",
      "Exiting the chat. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "   \n",
    "    # Initialize your custom client with the API key\n",
    "    allin_path = \"all.json\"\n",
    "    client = GPT()\n",
    "   #messages=[{'role': 'system', 'content': 'You are an assistant ,that gives a perfmon event counter to detect attack by given the decription of the attack'}]\n",
    "    \n",
    "    t=1\n",
    "    while 1:\n",
    "        print(\"user :\")\n",
    "        user_reply=input().strip()\n",
    "        # Exit the loop if the user types \"exit\" or \"quit\"\n",
    "        if user_reply.lower() in {\"exit\", \"quit\"}:\n",
    "            append_to_json(allin_path, messages)\n",
    "            print(\"Exiting the chat. Goodbye!\")\n",
    "            break\n",
    "        messages.append({'role': 'user','content':f\"{user_reply}\"})\n",
    "        print(user_reply)\n",
    "        #Get the GPT response using your custom client\n",
    "        response = client.get_gpt_response(messages)\n",
    "\n",
    "        tool_calls = response.choices[0].message.tool_calls\n",
    "        #print(tool_calls)\n",
    "        available_functions = {\n",
    "                \"perform_bimodal_test\": GPT.perform_bimodal_test,\n",
    "                \"plot_a graph\":GPT.plot_a_graph,\n",
    "            }\n",
    "        if(tool_calls and \"perform a diptest\" in user_reply.lower()) :\n",
    "            '''gpt_response = {\n",
    "            \"role\": response.choices[0].message.role,\n",
    "            \"content\": response.choices[0].message\n",
    "            }'''\n",
    "            messages.append(response.choices[0].message)\n",
    "            for tool_call in tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_to_call = available_functions[function_name]\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "                \n",
    "                if function_args.get(\"filepath\").endswith(\".txt\"):\n",
    "                    function_response = function_to_call(filepath=function_args.get(\"filepath\"))\n",
    "                    file_id=GPT.upload_file(function_args.get(\"filepath\"))\n",
    "                    \n",
    "                    # Append the function response back to the conversation\n",
    "                    messages.append(\n",
    "                        {\n",
    "                            \"tool_call_id\": tool_call.id,\n",
    "                            \"role\": \"tool\",\n",
    "                            \"name\": function_name,\n",
    "                            \"content\": function_response,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "            response = client.get_gpt_response(messages)\n",
    "            messages.append({'role':'assistant','content':f\"{response.choices[0].message.content}\"})\n",
    "            print(\"GPT Response:\", response.choices[0].message.content)\n",
    "        elif(tool_calls and  \"plot a graph\" in user_reply.lower()):\n",
    "            '''gpt_response = {\n",
    "            \"role\": response.choices[0].message.role,\n",
    "            \"content\": response.choices[0].message\n",
    "            }'''\n",
    "            messages.append(response.choices[0].message)\n",
    "            for tool_call in tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_to_call = available_functions[function_name]\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "                if function_args.get(\"filepath\").endswith(\".txt\"):\n",
    "                    function_response = function_to_call(filepath=function_args.get(\"filepath\"))\n",
    "                    # Append the function response back to the conversation\n",
    "                    messages.append(\n",
    "                        {\n",
    "                            \"tool_call_id\": tool_call.id,\n",
    "                            \"role\": \"tool\",\n",
    "                            \"name\": function_name,\n",
    "                            \"content\": function_response,\n",
    "                        }\n",
    "                    )\n",
    "            #img_html = f'<img src=\"data:image/png;base64,{function_response}\" alt=\"Graph\">'\n",
    "            #print(f\"Here is your graph:\\n{img_html}\")\n",
    "            response = client.get_gpt_response(messages)\n",
    "            messages.append({'role':'assistant','content':f\"{response.choices[0].message.content}\"})\n",
    "            print(\"GPT Response:\", response.choices[0].message.content)\n",
    "        else:\n",
    "            role=response.choices[0].message.role\n",
    "            content=response.choices[0].message.content\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"role\":role,\n",
    "                    \"content\":content\n",
    "                }\n",
    "            )\n",
    "            print(\"GPT Response:\", response.choices[0].message.content)\n",
    "\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'perfw_CPU_CLK_UNHALTED_THREAD_P.txt'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response.choices[0].message.tool_calls[0].function.arguments).get('filepath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dip_stat: 0.03286805555555555, p_value: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(GPT.perform_unimodal_test(filepath=json.loads(response.choices[0].message.tool_calls[0].function.arguments).get('filepath')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an assistant ,that gives a perfmon event counter from the site https://perfmon-events.intel.com/ to detect attack by given the decription of the attack and machine model'},\n",
       " {'role': 'user',\n",
       "  'content': 'I am performing RSA encryption and decryption.Can you suggest set of  counters name for alder lake system from intel perfmon that could potentially be used to detect speculative execution  with Croos-Modifying Code Machine Clear on my system.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vir_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
